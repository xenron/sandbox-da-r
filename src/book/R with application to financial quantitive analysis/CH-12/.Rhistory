}
else i2 = i
}
a$lambda[count] = weighted.mean(a$lambda[i1:i2], a$pi[i1:i2])
a$pi[count] = sum(a$pi[i1:i2])
poismix(lambda=a$lambda[1:count], pi=a$pi[1:count])
}
# Approximately equal
aeq.poismix = function(a, b, precision=c(1e-6,1e-6)) {
if( is.null(a) && is.null(b) ) return( TRUE )
if( is.null(a) || is.null(b) ) return( FALSE )
if( length(a$lambda) != length(b$lambda) ) return( FALSE )
if( max(abs(a$lambda - b$lambda) / sqrt(pmin(a$lambda, b$lambda)+1e-20))
>= precision[1] )
return( FALSE )
if( max(abs(a$pi - b$pi)) >= precision[2]) return( FALSE )
TRUE
}
# Returns a random sample of a Poisson mixture
# n        Sample size
# lambda   Means
# pi       Proportions for all components
# fixed    = TRUE, proportion of observations from each component is fixed
rpoismix = function(n=50, lambda=c(1,4), pi=1, mix, fixed=TRUE) {
if( ! missing(mix) ) {lambda =  mix$lambda; pi=mix$pi}
if( n == 0 ) return( numeric(0) )
k = length(lambda)
pi = rep(pi, len=k)
pi = pi / sum(pi)
if( fixed ) {
nj = floor(n * pi)
x = rpoismix(n - sum(nj), lambda=lambda, pi=pi, fixed=FALSE)
}
else {
cs = colSums(outer(runif(n), cumsum(pi), "<"))
nj = c(cs[1], diff(cs))
x = numeric(0)
}
for( j in 1:k ) x = c(x, rpois(nj[j], lambda[j]))
sample(x)
}
# ---------------------- #
# Distribution functions #
# ---------------------- #
# Density function of a Poisson mixture
dpoismix = function(a, x, log=FALSE) {
log.dpois = function(x, lambda) dpois(x, lambda, log=TRUE)
if (log) {
logd = outer(x, a$lambda, log.dpois)
ma = apply(logd, 1, max)
ma + log(rowSums(sweep(exp(sweep(logd, 1, ma, "-")), 2, a$pi, "*")))
}
else rowSums(sweep(outer(x, a$lambda, dpois), 2, a$pi, "*"))
}
# log-likelihood
logLik.poismix = function( a, x, w=1 ) sum( w * dpoismix(a, x, log=TRUE) )
# Line search
# mix1      Current poismix object
# mix2      New poismix object
# x         Observations
# w         Frequency
# ll.mix1   log-likelihood of mix1
# lsm       Line search method, either step-halving (halving) or optimal (optim)
line.poismix = function(mix1, mix2, x, w, ll.mix1=NULL,
lsm=c("halving","optim")) {
lsm = match.arg(lsm)
ll.alpha = function(alpha) {
m = poismix( (1-alpha) * mix1$lambda + alpha * mix2$lambda,
(1-alpha) * mix1$pi + alpha * mix2$pi )
logLik(m, x, w)
}
if( is.null(ll.mix1) ) ll.mix1 = logLik(mix2, x, w)
convergence = 0
alpha = 1
repeat {
if( lsm == "optim" ) {
m = poismix( (1-alpha) * mix1$lambda + alpha * mix2$lambda,
(1-alpha) * mix1$pi + alpha * mix2$pi )
d = m$pi - mix1$pi
gll = sum(gradient.poismix(m, x, w)$gradient * d)
if( gll < 0 ) alpha = optimize(ll.alpha, lower=0, upper=alpha, max=TRUE,
tol=1e-3)$maximum
}
ll.mix = ll.alpha(alpha)
if( ll.mix > ll.mix1 ) break
if( alpha < 1e-10 ) {convergence = 1; break}
alpha = alpha / 2
}
list(mix = poismix((1-alpha) * mix1$lambda + alpha * mix2$lambda,
(1-alpha) * mix1$pi + alpha * mix2$pi),
ll.mix=ll.mix, alpha=alpha, convergence=convergence)
}
# Gradient of the log-likelihood
gradient.poismix = function(mix, x, w, individual=FALSE,
hessian=FALSE) {
dij = outer(x, mix$lambda, dpois)
di = as.vector(dij %*% mix$pi)
gradient.i = w * dij / di
if( individual ) list( gradient = gradient.i )
else list( gradient = colSums(gradient.i) )
}
mix.efron = normmix(mu=c(-10.9, -7.0, -4.9, -1.8, -1.1, 0.0, 2.4, 6.1),
pi=c(1.5, 1.3, 5.6, 12.3, 13.6, 60.8, 2.7, 2.2))
set.seed(1)
x = rnormmix(n=1000, mix=mix.efron)
cnm.normmix(x, tol=1e-5)
thai = data.frame( x=c(0:21,23,24),
freq=c(120,64,69,72,54,35,36,25,25,19,18,18,13,4,3,6,6,5,1,3,1,2,1,2) )
cnm.poismix(x=thai$x, w=thai$freq)
nnls
library(quantreg)
?rq
rq
rq.fit
rq.fit.fnb
cnm.normmix(x, tol=1e-5)
cnm.poismix(x=thai$x, w=thai$freq)
install.packages('ctm')
install.packages("ctm", repos="http://R-Forge.R-project.org")
library(ctm)
install.packages("ctmDevel", repos="http://R-Forge.R-project.org")
install.packages("ctmDevel", repos="http://R-Forge.R-project.org")
library(ctm)
library(ctm)
library(ctm)
help(package='ctm')
install.packages("ctmDevel", repos="http://R-Forge.R-project.org")
install.packages("ctmDevel", repos="http://R-Forge.R-project.org")
# 0. 初始化
setwd('J:/programe/book/R with application to financial quantitive analysis/CH-05')
rm(list=ls())
# 1. 加载包
library(fGarch)
# 2. 模拟一元ARCH时间序列模型
# (1) simulate ARCH(1) model
set.seed(12345)
spec_1 <- garchSpec(model=list(omega=0.01, alpha=0.85, beta=0))
simdata_1 <- garchSim(spec_1, n=200, extended=TRUE)
class(simdata_1)
plot(simdata_1)
par(mfrow=c(1,3))
acf(simdata_1$eps, main='(a) residual series')
acf(simdata_1$garch, main='(b) simulate data')
acf(simdata_1$garch^2, main='(c) squared simulate data')
sumsq <- function(x){
y <- sum(x^2)
y
}
xx <- 1:5
sumsq(xx)
?lm
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group)
names(lm.D9)
sumsq <- function(x){
y <- sum(x^2)
y
}
res <- function(y, x){
model.lm <- lm(y~x)
res <- model.lm$residuals
res
}
Q <- function(y, x){
ress <- res(y,x)
Q <- sumsq(ress)
Q
}
x <- seq(-5, 5, length=100)
y <- 5+2*x+rnorm(100)
Qstat <- Q(y, x)
Qstat
x <- seq(-5, 5, length=100)
y <- 10+3*x+rnorm(100)
Qstat <- Q(y, x)
Qstat
library(PerformanceAnalytics)
?CAPM.jensenAlpha
install.packages('fOption')
help(package='lmtest')
help(package='vars')
?read
?read.table
?save
?write
library(xlsx)
install.packages('xlsx')
library(xlsx)
library(xlsx)
library(xlsx)
library(ROCR)                     # for ROCR curve
install.packages('ROCR')
library(ROCR)                     # for ROCR curve
data=read.delim("clipboard")
data <- dat
data= data[sample(1:nrow(data),length(1:nrow(data))),1:ncol(data)]
install.packages('RSNNS')
library(RSNNS)
library(RSNNS)
install.packages('Rcpp')
library(RSNNS)
data=read.delim("clipboard")
data <- dat
data= data[sample(1:nrow(data),length(1:nrow(data))),1:ncol(data)]
dataValues= data[,1:7]
dataTargets = decodeClassLabels(data[,8])
data=splitForTrainingAndTest(dataValues, dataTargets, ratio=0.30)
data=normTrainingAndTestSet(data)
#建立rbf神经网络，并且训练
model2=rbf(data$inputsTrain,data$targetsTrain)
#预测
predictions2 = predict(model2,data$inputsTest)
#结果展示
confusionMatrix(data$targetsTest,predictions2)
?rbf
data
x <- as.matrix(data[,1:7])
dim(data)
data=read.delim("clipboard")
dat <- data
x <- as.matrix(dat[,1:7])
y <- as.matrix(dat[,8])
model.RBF <- rbf(inputs=x, outputs=y, size=40, maxit=1000)
x
y
dim(x)
dim(y)
model.RBF <- rbf(inputs=x, outputs=y, size=40, maxit=1000)
inputs <- as.matrix(seq(0,10,0.1))
outputs <- as.matrix(sin(inputs) + runif(inputs*0.2))
outputs <- normalizeData(outputs, "0_1")
model <- rbf(inputs, outputs, size=40, maxit=1000,
initFuncParams=c(0, 1, 0, 0.01, 0.01),
learnFuncParams=c(1e-8, 0, 1e-8, 0.1, 0.8), linOut=TRUE)
inputs
dim(inputs)
dim(outputs)
model.RBF <- rbf(inputs=x, outputs=y, size=40, maxit=1000)
model.RBF <- rbf(inputs=x, outputs=y, maxit=1000)
model.RBF <- rbf(inputs=x, outputs=y, size=3, maxit=1000)
model <- rbf(inputs, outputs, size=40, maxit=1000)
dim(x)
dim(y)
dim(inputs)
dim(outputs)
model.RBF <- rbf(inputs=x, outputs=y)
y
y
x
as.matrix(sin(inputs) + runif(inputs*0.2))
normalizeData(outputs, "0_1")
model.RBF <- rbf(inputs=x, outputs=normalizeData(y, "0_1"), size=3, maxit=1000)
normalizeData(y, "0_1")
rbf(inputs=x, outputs=normalizeData(y, "0_1"), size=3, maxit=1000)
inputs <- as.matrix(seq(0,10,0.1))
outputs <- as.matrix(sin(inputs) + runif(inputs*0.2))
inputs
outputs
outputs <- normalizeData(outputs, "0_1")
outputs
model <- rbf(inputs, outputs, size=40, maxit=1000)
inputs=x
outputs=normalizeData(y, "0_1")
inputs
class(inputs)
colnames(inputs)
colnames(inputs)<-''
colnames(inputs)<-NULL
head(inputs)
rbf(inputs, outputs)
rbf(inputs, outputs, maxit=1000)
inputs <- as.matrix(seq(0,10,0.1))
outputs <- as.matrix(sin(inputs) + runif(inputs*0.2))
outputs <- normalizeData(outputs, "0_1")
model <- rbf(inputs, outputs, size=40, maxit=1000)
rbf(inputs, outputs, size=40, maxit=1000)
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
dataTargets <- decodeClassLabels(y)
model.RBF <- rbf(inputs, outputs, size=3, maxit=1000)
model.RBF
par(mfrow=c(2,1))
plotIterativeError(model.RBF)
plot(inputs, outputs)
lines(inputs, fitted(model.RBF), col="green")
plotIterativeError(model.RBF)               # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)             # calculate confusion matrix
install.packages('DAAG')
DAAG::confusion(round(y.hat), y)             # calculate confusion matrix
library(DAAG)
install.packages('DAAG')
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
par(mfrow=c(1,1))
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
dataTargets <- decodeClassLabels(y)
model.RBF <- rbf(inputs, outputs, size=5, maxit=1000)
# (2) show results
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
# 4. make RBF neural network
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
dataTargets <- decodeClassLabels(y)
model.RBF <- rbf(inputs, outputs, size=15, maxit=1000)
# (2) show results
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
# 4. make RBF neural network
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
model.RBF <- rbf(inputs, outputs, size=10, maxit=1000)
# (2) show results
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
# 4. make RBF neural network
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
model.RBF <- rbf(inputs, outputs, size=10, maxit=1000)
# (2) show results
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
# 4. make RBF neural network
# (1) estimate model
set.seed(12345)
inputs <- x
colnames(inputs) <- NULL
outputs <- normalizeData(y, "0_1")
model.RBF <- rbf(inputs, outputs, size=10, maxit=1000)
# (2) show results
plotIterativeError(model.RBF)                              # show iterations
y.hat <- predict(model.RBF, inputs)
DAAG::confusion(round(y.hat), y)                           # calculate confusion matrix
plot(performance(prediction(y.hat, y), "tpr","fpr"))       # plot ROC
performance(prediction(y.hat, y), "auc")@y.values[[1]]     # accuracy
# 0. initializing
# (1) set path
setwd('F:/programe/book/R with application to financial quantitive analysis/CH-12')
rm(list=ls())
# (2) load packages
library(xlsx)                   # for reading EXCEL file
library(zoo)                    # for time series
library(xts)                    # for time series
library(quantreg)               # for quantile regression
source('Sub-12.R')              # our own functions
# 1. read data from EXCEL file
# (1) read raw data
StratInd <- read.xlsx(file='FundPerfData.xlsx', sheetName='Strategy')
r.ThreeFactor <- read.xlsx(file='FundPerfData.xlsx', sheetName='threefactors')
r.StyFactor_1 <- read.xlsx(file='FundPerfData.xlsx', sheetName='stylefactors')
r.StyFactor_2 <- read.xlsx(file='FundPerfData.xlsx', sheetName='bonds')
benchreturn <- read.xlsx(file='FundPerfData.xlsx', sheetName='benchmark')
# (2) interplote data
StratInd$RV <- na.approx(StratInd$RV)
StratInd$MF <- na.approx(StratInd$MF)
StratInd$ED <- na.approx(StratInd$ED)
# (3) data frequency and treat as time series
StratInd.xts <- data.freq(StratInd, freq='Month')
r.ThreeFactor.xts <- data.freq(r.ThreeFactor, freq='Month')
r.StyFactor_1.xts <- data.freq(r.StyFactor_1, freq='Month')
r.StyFactor_2.xts <- data.freq(r.StyFactor_2, freq='Month')
benchreturn.xts <- data.freq(benchreturn, freq='Month')
# (4) compute returns
r.StratInd.xts <- diff(log(StratInd.xts))
r.StratInd.xts <- r.StratInd.xts[-1,]
# (5) merge data
data_Str.Thr <- merge(r.StratInd.xts, r.ThreeFactor.xts, join='inner')
data_Str.Thr.Sty1 <- merge(data_Str.Thr, r.StyFactor_1.xts, join='inner')
data_Str.Thr.Sty1.Sty2 <- merge(data_Str.Thr.Sty1, r.StyFactor_2.xts, join='inner')
# (6) renames and attach data
sample_data <- data_Str.Thr.Sty1.Sty2
names.strat <- c('RV', 'MF', 'ES', 'FI', 'M', 'ED', 'FOF')
names.fact <- c('RF', 'SMB', 'HML', 'OPG', 'OPV', 'TPG', 'TPV', 'SPG', 'SPV', 'TB', 'CB')
X <- as.matrix(sample_data[,names.fact])
Y <- as.matrix(sample_data[,names.strat])
colnames(Y) <- names.strat
attach(as.data.frame(sample_data))
BP <- benchreturn.xts$BP
# 2. calculate risk measurment indicators
sd(RV)                                                                    # standard deviation
(rou<-cor(cbind(RV=RV,BP)))                                                  # correlation coefficient
(beta<-rou*sd(RV)/sd(BP))                                                 # beta coefficient
(Down.Risk <- sqrt(sum(pmin(0, RV)^2)/length(RV)))                        # downside risk
# 4. do mean regression
# (1) do stepwise regression
lm.sol<-lm(RV~RF+SMB+HML+OPG+OPV+TPG+TPV+SPG+SPV+TB+CB)                   #linear regression
summary(lm.sol)
lm.step<-step(lm.sol)                                                     #step regression
summary(lm.step)
#（2）calculate Jesen indices
alpha_mr <- numeric(length(names.strat))
names.sig_mr <- list()
for (i in 1:length(names.strat)){
temp.mr <- meanreg(Y=Y[,names.strat[i]], X=X)
alpha_mr[i] <- temp.mr$alpha
names.sig_mr[[i]] <- temp.mr$names.sig
}
names(alpha_mr) <- names.strat
print(alpha_mr)
library(xlsx)                   # for reading EXCEL file
library(zoo)                    # for time series
library(xts)                    # for time series
library(quantreg)               # for quantile regression
source('Sub-12.R')              # our own functions
# 2. calculate risk measurment indicators
sd(RV)                                                                    # standard deviation
(rou<-cor(cbind(RV=RV,BP)))                                                  # correlation coefficient
(beta<-rou*sd(RV)/sd(BP))                                                 # beta coefficient
(Down.Risk <- sqrt(sum(pmin(0, RV)^2)/length(RV)))                        # downside risk
# 3. calculate performance measurment indicators
(TR<-mean(RV)/beta[1,2])                                                  # TR ratio
(ShR<-mean(RV)/sd(RV))                                                    # ShR ratio
(SoR<-mean(RV)/Down.Risk)                                                 # SoR ratio
# 4. do mean regression
# (1) do stepwise regression
lm.sol<-lm(RV~RF+SMB+HML+OPG+OPV+TPG+TPV+SPG+SPV+TB+CB)                   #linear regression
summary(lm.sol)
lm.step<-step(lm.sol)                                                     #step regression
summary(lm.step)
#（2）calculate Jesen indices
alpha_mr <- numeric(length(names.strat))
names.sig_mr <- list()
for (i in 1:length(names.strat)){
temp.mr <- meanreg(Y=Y[,names.strat[i]], X=X)
alpha_mr[i] <- temp.mr$alpha
names.sig_mr[[i]] <- temp.mr$names.sig
}
names(alpha_mr) <- names.strat
print(alpha_mr)
# 5. do quantile regression
# (1) optimal lambda and optimal AIC
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
lambdas <- seq(0, 0.1, by=0.001)
lamdsOpt <- matrix(NA, nrow=length(names.strat), ncol=length(taus))
rownames(lamdsOpt) <- names.strat
colnames(lamdsOpt) <- paste('tau=', taus)
AICsOpt <- matrix(NA, nrow=length(names.strat), ncol=length(taus))
rownames(AICsOpt) <- names.strat
colnames(AICsOpt) <- paste('tau=', taus)
for (i in 1:length(names.strat)){
temp.sel <- sel.labmda(Y=Y[,i], X=X, taus, lambdas)
lamdsOpt[i,] <- temp.sel$lambdasOpt
AICsOpt[i,] <- temp.sel$AICOpt
}
lamdsOpt
AICsOpt
(coefs_1 <- selParms(Y=Y[,1], X, taus, lamdsOpt, names.fact))
coefs_2 <- selParms(Y=Y[,2], X, taus, lamdsOpt, names.fact)
coefs_3 <- selParms(Y=Y[,3], X, taus, lamdsOpt, names.fact)
coefs_4 <- selParms(Y=Y[,4], X, taus, lamdsOpt, names.fact)
coefs_5 <- selParms(Y=Y[,5], X, taus, lamdsOpt, names.fact)
coefs_6 <- selParms(Y=Y[,6], X, taus, lamdsOpt, names.fact)
coefs_7 <- selParms(Y=Y[,7], X, taus, lamdsOpt, names.fact)
coefs_1 <- selParms(Y=Y[,1], X, taus, lamdsOpt, names.fact)
coefs_2 <- selParms(Y=Y[,2], X, taus, lamdsOpt, names.fact)
coefs_3 <- selParms(Y=Y[,3], X, taus, lamdsOpt, names.fact)
coefs_4 <- selParms(Y=Y[,4], X, taus, lamdsOpt, names.fact)
coefs_5 <- selParms(Y=Y[,5], X, taus, lamdsOpt, names.fact)
coefs_6 <- selParms(Y=Y[,6], X, taus, lamdsOpt, names.fact)
coefs_7 <- selParms(Y=Y[,7], X, taus, lamdsOpt, names.fact)
print(coefs_1)
#（3）alpha star indices
riskvalue <- seq(0, 1, by=0.2)
fund.names <- colnames(Y)
alpha_star <- matrix(NA, nrow=length(fund.names), ncol=length(riskvalue))
alpha_star[1,] <- coefs_1[1, 3] - riskvalue/2*(coefs_1[1, 4]-coefs_1[1, 2])
alpha_star[2,] <- coefs_2[1, 3] - riskvalue/2*(coefs_2[1, 4]-coefs_2[1, 2])
alpha_star[3,] <- coefs_3[1, 3] - riskvalue/2*(coefs_3[1, 4]-coefs_3[1, 2])
alpha_star[4,] <- coefs_4[1, 3] - riskvalue/2*(coefs_4[1, 4]-coefs_4[1, 2])
alpha_star[5,] <- coefs_5[1, 3] - riskvalue/2*(coefs_5[1, 4]-coefs_5[1, 2])
alpha_star[6,] <- coefs_6[1, 3] - riskvalue/2*(coefs_6[1, 4]-coefs_6[1, 2])
alpha_star[7,] <- coefs_7[1, 3] - riskvalue/2*(coefs_7[1, 4]-coefs_7[1, 2])
rownames(alpha_star) <- fund.names
colnames(alpha_star) <- paste('riskvalue=', riskvalue, sep='')
print(alpha_star)
library(rmr2)                             #载入rmr2程序包
install.packages('rmr2')
